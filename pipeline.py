# pipeline.py
import os
import shutil
import logging
from datetime import datetime, timezone
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt
import catboost as cb
from sklearn.metrics import (
    accuracy_score, classification_report, f1_score,
    ConfusionMatrixDisplay
)

from pybit.unified_trading import HTTP
from config import BYBIT_API_KEY, BYBIT_API_SECRET, CONFIDENCE_THRESHOLDS
from data_loader import set_client

from model_trainer import (
    prepare_data,
    optimize_catboost,
    train_final_model,
    rolling_cross_validation,
)

# --- setup ---
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

OUTPUT_DIR = Path("outputs")
MODEL_DIR = Path("models")
OUTPUT_DIR.mkdir(exist_ok=True)
MODEL_DIR.mkdir(exist_ok=True)


def evaluate_model(model: cb.CatBoostClassifier, X_test, y_test, symbol: str, ts: str):
    """–°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏, –ø–∏—à–µ–º –æ—Ç—á—ë—Ç—ã –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏."""
    proba = model.predict_proba(X_test)
    confidence = np.max(proba, axis=1)
    y_pred = np.argmax(proba, axis=1)

    logger.info("=" * 30 + f" [FINAL METRICS] {symbol} " + "=" * 30)
    logger.info("[All] Accuracy: %.4f", accuracy_score(y_test, y_pred))
    logger.info("[All] F1 macro: %.4f", f1_score(y_test, y_pred, average="macro"))

    labels_order = [0, 1, 2]
    target_names = ["Down", "Up", "Neutral"]
    report = classification_report(
        y_test, y_pred, labels=labels_order, target_names=target_names, zero_division=0
    )
    (OUTPUT_DIR / f"{symbol}_{ts}_report.txt").write_text(report)

    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap="viridis")
    plt.title(f"Confusion Matrix ({symbol})")
    plt.savefig(OUTPUT_DIR / f"{symbol}_{ts}_confusion_matrix.png")
    plt.close()

    # –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø–æ—Ä–æ–≥–∞–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    for thr in CONFIDENCE_THRESHOLDS:
        idx = confidence >= thr
        if np.any(idx):
            acc = accuracy_score(y_test[idx], y_pred[idx])
            f1 = f1_score(y_test[idx], y_pred[idx], average="macro")
            logger.info(f"[Conf >= {thr:.2f}] Accuracy: {acc:.4f}, F1_macro: {f1:.4f}")
        else:
            logger.warning(f"–ù–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø—Ä–∏ –ø–æ—Ä–æ–≥–µ {thr:.2f}")

    # –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏ CatBoost –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é ‚Äî –ø–æ–¥—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è)
    importances = model.get_feature_importance(prettified=True)
    plt.figure(figsize=(10, 6))
    feat_col = "Feature Id" if "Feature Id" in importances.columns else (
        "Feature" if "Feature" in importances.columns else importances.columns[0]
    )
    val_col = "Importances" if "Importances" in importances.columns else importances.columns[-1]
    plt.barh(importances[feat_col], importances[val_col])
    plt.title("CatBoost Feature Importances")
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / f"{symbol}_{ts}_feature_importance.png")
    plt.close()


def _timestamp() -> str:
    return datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")


def _archive_artifacts(symbol: str, ts: str):
    """
    –ö–æ–ø–∏—Ä—É–µ–º —Å–≤–µ–∂–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ç—Ä–µ–Ω–µ—Ä–∞ –≤ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É:
    models/{symbol}/{ts}/(model.cbm, scaler.pkl, cat_features.pkl)
    + –ø–ª–æ—Å–∫–∏–µ —Ñ–∞–π–ª—ã model_{symbol}.cbm, scaler_{symbol}.pkl, cat_features_{symbol}.pkl
    """
    # –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –≥–¥–µ –∏—Ö —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç model_trainer
    model_src = MODEL_DIR / "saved_model.cbm"
    scaler_src = MODEL_DIR / "scaler.pkl"          # —Å–º. –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π save –≤ prepare_data()
    cat_src = MODEL_DIR / "cat_features.pkl"

    target_dir = MODEL_DIR / symbol / ts
    target_dir.mkdir(parents=True, exist_ok=True)

    def _safe_copy(src: Path, dst: Path, label: str):
        try:
            if src.exists():
                shutil.copyfile(src, dst)
                logger.info(f"{label} —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ {dst}")
            else:
                logger.warning(f"{label} –Ω–µ –Ω–∞–π–¥–µ–Ω: {src}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å {label}: {e}")

    # –≤ timestamp-–ø–∞–ø–∫—É
    _safe_copy(model_src, target_dir / "model.cbm", "–ú–æ–¥–µ–ª—å")
    _safe_copy(scaler_src, target_dir / "scaler.pkl", "–°–∫–µ–π–ª–µ—Ä")
    _safe_copy(cat_src,    target_dir / "cat_features.pkl", "cat_features")

    # –ø–ª–æ—Å–∫–∏–µ –∞–ª–∏–∞—Å—ã –ø–æ —Å–∏–º–≤–æ–ª—É (—É–¥–æ–±–Ω–æ –∏—Å–∫–∞—Ç—å)
    _safe_copy(model_src, MODEL_DIR / f"model_{symbol}.cbm", "–ú–æ–¥–µ–ª—å (–∞–ª–∏–∞—Å)")
    _safe_copy(scaler_src, MODEL_DIR / f"scaler_{symbol}.pkl", "–°–∫–µ–π–ª–µ—Ä (–∞–ª–∏–∞—Å)")
    _safe_copy(cat_src,    MODEL_DIR / f"cat_features_{symbol}.pkl", "cat_features (–∞–ª–∏–∞—Å)")

    return target_dir


def train_on_symbol(symbol: str, interval: str = "15", threshold: float = 0.0015, use_rolling_cv: bool = True):
    logger.info(f"‚öôÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}‚Ä¶")
    ts = _timestamp()

    # 1) –¥–∞–Ω–Ω—ã–µ
    X_train, X_test, y_train, y_test = prepare_data(symbol, interval, threshold)
    logger.info(f"Train size: {len(X_train)} | Test size: {len(X_test)}")

    # 2) –±—ã—Å—Ç—Ä–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–æ–≤
    best_params = optimize_catboost(X_train, y_train)

    # 3) rolling CV (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if use_rolling_cv:
        scores = rolling_cross_validation(X_train, y_train, best_params, n_splits=5)
        logger.info("üìà Rolling CV F1_macro: %.4f", float(np.mean(scores)))

    # 4) —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (model_trainer —Å–∞–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ models/)
    train_final_model(X_train, y_train, best_params)

    # 5) –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Å–≤–µ–∂–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø–æ–¥ —Å–∏–º–≤–æ–ª/—Ç–∞–π–º—Å—Ç–µ–º–ø
    run_dir = _archive_artifacts(symbol, ts)

    # 6) –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ–∂—É—é –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    model = cb.CatBoostClassifier()
    model.load_model(str(MODEL_DIR / "saved_model.cbm"))
    evaluate_model(model, X_test, y_test, symbol=symbol, ts=ts)

    logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è {symbol}. –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: {run_dir}")


if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Bybit –∫–ª–∏–µ–Ω—Ç–∞ (–¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ OHLCV)
    client = HTTP(api_key=BYBIT_API_KEY, api_secret=BYBIT_API_SECRET)
    set_client(client)

    # –í—Ä–µ–º–µ–Ω–Ω–æ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ ‚Äî –ø–æ–∑–∂–µ –∑–∞–º–µ–Ω–∏–º –Ω–∞ top_pairs –∏–∑ pair_discovery
    symbols = ["BTCUSDT", "ETHUSDT"]

    for sym in symbols:
        train_on_symbol(sym)
